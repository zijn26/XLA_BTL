# Fix encoding for Windows console
import sys
import io
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from flask import Flask, request, jsonify
from flask_cors import CORS
import cv2
import numpy as np
import os
import base64
import pickle
import json
import h5py
from tensorflow import keras
import tensorflow as tf
from werkzeug.utils import secure_filename
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from tienxulyanh import (
    load_image, apply_histogram_equalization, convert_to_grayscale,
    apply_median_filter, apply_canny_edge_detection, segment_by_thresholding
)

app = Flask(__name__)
CORS(app)  # Cho ph√©p CORS ƒë·ªÉ frontend c√≥ th·ªÉ g·ªçi API

# C·∫•u h√¨nh
UPLOAD_FOLDER = 'uploads'
PROCESSED_FOLDER = 'processed_images'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}

# T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PROCESSED_FOLDER, exist_ok=True)

# Load model v√† label encoder
MODEL_PATH = 'fruit_recognition_cnn_2channel.h5'
LABEL_ENCODER_PATH = 'label_encoder (1).pkl'

model = None
label_encoder = None

def patch_model_config(model_path):
    """Patch model config ƒë·ªÉ fix l·ªói batch_shape v√† DTypePolicy"""
    try:
        import tempfile
        import shutil
        
        # T·∫°o file t·∫°m
        temp_path = model_path + '.patched'
        
        # Copy file g·ªëc
        shutil.copy2(model_path, temp_path)
        
        # ƒê·ªçc v√† s·ª≠a config
        with h5py.File(temp_path, 'r+') as f:
            # T√¨m config trong attributes
            if 'model_config' in f.attrs:
                config_str = f.attrs['model_config']
                if isinstance(config_str, bytes):
                    config_str = config_str.decode('utf-8')
                
                config = json.loads(config_str)
                
                # H√†m ƒë·ªá quy ƒë·ªÉ s·ª≠a config
                def fix_config(obj):
                    if isinstance(obj, dict):
                        # S·ª≠a InputLayer - batch_shape
                        if obj.get('class_name') == 'InputLayer' and 'config' in obj:
                            if 'batch_shape' in obj['config']:
                                batch_shape = obj['config'].pop('batch_shape')
                                if batch_shape and len(batch_shape) > 1:
                                    obj['config']['input_shape'] = list(batch_shape[1:])
                        
                        # S·ª≠a dtype - DTypePolicy th√†nh string
                        if 'config' in obj:
                            config_dict = obj['config']
                            if 'dtype' in config_dict:
                                dtype_val = config_dict['dtype']
                                if isinstance(dtype_val, dict):
                                    # N·∫øu l√† DTypePolicy object, chuy·ªÉn th√†nh string
                                    if dtype_val.get('class_name') == 'DTypePolicy':
                                        dtype_name = dtype_val.get('config', {}).get('name', 'float32')
                                        config_dict['dtype'] = dtype_name
                                    elif 'class_name' in dtype_val:
                                        # C√°c dtype policy kh√°c
                                        dtype_name = dtype_val.get('config', {}).get('name', 'float32')
                                        config_dict['dtype'] = dtype_name
                        
                        # ƒê·ªá quy cho c√°c key kh√°c
                        for key, value in obj.items():
                            fix_config(value)
                    elif isinstance(obj, list):
                        for item in obj:
                            fix_config(item)
                
                fix_config(config)
                
                # Ghi l·∫°i config ƒë√£ s·ª≠a
                f.attrs['model_config'] = json.dumps(config).encode('utf-8')
                print("‚úÖ ƒê√£ patch model config (batch_shape + DTypePolicy)!")
        
        return temp_path
    except Exception as e:
        print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ patch config: {e}")
        return model_path

def load_model_with_compatibility(model_path):
    """Load model v·ªõi c√°c c√°ch t∆∞∆°ng th√≠ch kh√°c nhau"""
    # C√°ch 1: Th·ª≠ patch config tr∆∞·ªõc r·ªìi load v·ªõi custom_objects
    try:
        patched_path = patch_model_config(model_path)
        
        # T·∫°o custom objects ƒë·ªÉ x·ª≠ l√Ω DTypePolicy v√† batch_shape
        def fix_dtype_policy(config):
            """Fix DTypePolicy trong config"""
            if isinstance(config, dict) and 'dtype' in config:
                dtype_val = config['dtype']
                if isinstance(dtype_val, dict) and dtype_val.get('class_name') == 'DTypePolicy':
                    dtype_name = dtype_val.get('config', {}).get('name', 'float32')
                    config['dtype'] = dtype_name
            return config
        
        # Custom InputLayer ƒë·ªÉ x·ª≠ l√Ω batch_shape
        class CompatibleInputLayer(tf.keras.layers.InputLayer):
            @classmethod
            def from_config(cls, config):
                config = fix_dtype_policy(config)
                if 'batch_shape' in config:
                    batch_shape = config.pop('batch_shape')
                    if batch_shape and len(batch_shape) > 1:
                        config['input_shape'] = tuple(batch_shape[1:])
                return super().from_config(config)
        
        # Custom Conv2D v√† c√°c layer kh√°c ƒë·ªÉ x·ª≠ l√Ω DTypePolicy
        class CompatibleConv2D(tf.keras.layers.Conv2D):
            @classmethod
            def from_config(cls, config):
                config = fix_dtype_policy(config)
                return super().from_config(config)
        
        custom_objects = {
            'InputLayer': CompatibleInputLayer,
            'Conv2D': CompatibleConv2D,
        }
        
        model = keras.models.load_model(patched_path, compile=False, custom_objects=custom_objects)
        
        # X√≥a file patched n·∫øu kh√°c file g·ªëc
        if patched_path != model_path and os.path.exists(patched_path):
            try:
                os.remove(patched_path)
            except:
                pass
        return model, "patched_config_with_custom_objects"
    except Exception as e1:
        print(f"‚ö†Ô∏è  C√°ch 1 (patch + custom) th·∫•t b·∫°i: {str(e1)[:150]}")
        
        # C√°ch 2: Load v·ªõi custom_objects m√† kh√¥ng patch
        try:
            # T·∫°o custom objects ƒë·ªÉ x·ª≠ l√Ω DTypePolicy
            def create_compatible_layer(base_class):
                class CompatibleLayer(base_class):
                    @classmethod
                    def from_config(cls, config):
                        if isinstance(config, dict) and 'dtype' in config:
                            dtype_val = config['dtype']
                            if isinstance(dtype_val, dict):
                                if dtype_val.get('class_name') == 'DTypePolicy':
                                    config['dtype'] = dtype_val.get('config', {}).get('name', 'float32')
                                elif 'class_name' in dtype_val:
                                    config['dtype'] = dtype_val.get('config', {}).get('name', 'float32')
                        # Fix batch_shape cho InputLayer
                        if base_class == tf.keras.layers.InputLayer and 'batch_shape' in config:
                            batch_shape = config.pop('batch_shape')
                            if batch_shape and len(batch_shape) > 1:
                                config['input_shape'] = tuple(batch_shape[1:])
                        return super().from_config(config)
                return CompatibleLayer
            
            custom_objects = {
                'InputLayer': create_compatible_layer(tf.keras.layers.InputLayer),
                'Conv2D': create_compatible_layer(tf.keras.layers.Conv2D),
                'MaxPooling2D': create_compatible_layer(tf.keras.layers.MaxPooling2D),
                'Dense': create_compatible_layer(tf.keras.layers.Dense),
                'Flatten': create_compatible_layer(tf.keras.layers.Flatten),
                'Dropout': create_compatible_layer(tf.keras.layers.Dropout),
            }
            
            return keras.models.load_model(model_path, compile=False, custom_objects=custom_objects), "custom_objects_only"
        except Exception as e2:
            print(f"‚ö†Ô∏è  C√°ch 2 th·∫•t b·∫°i: {str(e2)[:150]}")
            
            # C√°ch 3: Load b√¨nh th∆∞·ªùng (th·ª≠ l·∫ßn cu·ªëi)
            try:
                return keras.models.load_model(model_path, compile=False), "compile=False"
            except Exception as e3:
                print(f"‚ö†Ô∏è  C√°ch 3 th·∫•t b·∫°i: {str(e3)[:150]}")
                raise Exception(f"Kh√¥ng th·ªÉ load model. L·ªói cu·ªëi: {e3}")

def load_model_and_encoder():
    """Load model v√† label encoder khi kh·ªüi ƒë·ªông app"""
    global model, label_encoder
    try:
        print("ƒêang load model...")
        
        # Load model v·ªõi c√°c c√°ch t∆∞∆°ng th√≠ch
        model, method = load_model_with_compatibility(MODEL_PATH)
        print(f"‚úÖ Model loaded successfully (s·ª≠ d·ª•ng: {method})!")
        
        print("ƒêang load label encoder...")
        with open(LABEL_ENCODER_PATH, 'rb') as f:
            label_encoder = pickle.load(f)
        print("‚úÖ Label encoder loaded successfully!")
        
    except Exception as e:
        print(f"‚ùå L·ªói khi load model/encoder: {e}")
        import traceback
        traceback.print_exc()
        print("\n" + "="*60)
        print("üí° G·ª£i √Ω kh·∫Øc ph·ª•c:")
        print("   1. C√†i ƒë·∫∑t TensorFlow 2.10.1: pip install tensorflow==2.10.1")
        print("   2. Ho·∫∑c rebuild model v·ªõi TensorFlow version m·ªõi")
        print("="*60)
        raise

def allowed_file(filename):
    """Ki·ªÉm tra file c√≥ ƒë√∫ng ƒë·ªãnh d·∫°ng kh√¥ng"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def image_to_base64(image_path):
    """Chuy·ªÉn ·∫£nh th√†nh base64 string"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode('utf-8')

def process_image_with_steps(image_path):
    """
    X·ª≠ l√Ω ·∫£nh qua c√°c b∆∞·ªõc gi·ªëng full_preprocessing_pipeline v√† l∆∞u k·∫øt qu·∫£ sau m·ªói b∆∞·ªõc.
    Logic gi·ªëng h·ªát full_preprocessing_pipeline trong tienxulyanh.py nh∆∞ng c√≥ th√™m ch·ª©c nƒÉng l∆∞u ·∫£nh.
    
    Returns:
        - processed_images: dict ch·ª©a c√°c ·∫£nh ƒë√£ x·ª≠ l√Ω (base64)
        - final_image: ·∫£nh cu·ªëi c√πng ƒë·ªÉ d·ª± ƒëo√°n (2 channel: grayscale + edge)
        - grayscale_image: ·∫£nh x√°m
        - saved_paths: dict ch·ª©a ƒë∆∞·ªùng d·∫´n c√°c file ƒë√£ l∆∞u
    """
    # B∆∞·ªõc 0: ƒê·ªçc ·∫£nh
    original_image = load_image(image_path)
    if original_image is None:
        return None, None, None, None
    
    original_image = cv2.resize(original_image, (100, 100))
    
    # T·∫°o unique ID cho session n√†y
    import time
    session_id = str(int(time.time() * 1000))
    
    processed_images = {}
    saved_paths = {}
    
    # I. L√†m s·∫°ch ·∫£nh v√† TƒÉng c∆∞·ªùng ch·∫•t l∆∞·ª£ng
    
    # 1. Chuy·ªÉn ·∫£nh x√°m
    grayscale_image = convert_to_grayscale(original_image)
    gray_path = os.path.join(PROCESSED_FOLDER, f'{session_id}_1_grayscale.jpg')
    cv2.imwrite(gray_path, grayscale_image)
    processed_images['1_grayscale'] = image_to_base64(gray_path)
    saved_paths['1_grayscale'] = gray_path
    
    # 2. C√¢n b·∫±ng histogram
    histogram_img = apply_histogram_equalization(grayscale_image)
    hist_path = os.path.join(PROCESSED_FOLDER, f'{session_id}_2_histogram.jpg')
    cv2.imwrite(hist_path, histogram_img)
    processed_images['2_histogram'] = image_to_base64(hist_path)
    saved_paths['2_histogram'] = hist_path
    
    # 3. Lo·∫°i b·ªè nhi·ªÖu b·∫±ng Median Filter
    denoised_image = apply_median_filter(grayscale_image)
    denoise_path = os.path.join(PROCESSED_FOLDER, f'{session_id}_3_denoised.jpg')
    cv2.imwrite(denoise_path, denoised_image)
    processed_images['3_denoised'] = image_to_base64(denoise_path)
    saved_paths['3_denoised'] = denoise_path
    
    # II. T√°ch ƒë·ªëi t∆∞·ª£ng (Segmentation)
    
    # 4. Ph√°t hi·ªán bi√™n b·∫±ng Canny (s·ª≠ d·ª•ng denoised_image)
    edge_image = apply_canny_edge_detection(denoised_image)
    edge_path = os.path.join(PROCESSED_FOLDER, f'{session_id}_4_edges.jpg')
    cv2.imwrite(edge_path, edge_image)
    processed_images['4_edges'] = image_to_base64(edge_path)
    saved_paths['4_edges'] = edge_path
    
    # 5. Ph∆∞∆°ng ph√°p Otsu (s·ª≠ d·ª•ng grayscale_image)
    otsu_img = segment_by_thresholding(grayscale_image)
    otsu_path = os.path.join(PROCESSED_FOLDER, f'{session_id}_5_otsu.jpg')
    cv2.imwrite(otsu_path, otsu_img)
    processed_images['5_otsu'] = image_to_base64(otsu_path)
    saved_paths['5_otsu'] = otsu_path
    
    # ·∫¢nh ƒë·∫ßu v√†o cho CNN (2 channel: grayscale + edge)
    # T·∫°o ·∫£nh 2 channel t·ª´ grayscale v√† edge
    final_image = np.stack([grayscale_image, edge_image], axis=-1)
    final_path = os.path.join(PROCESSED_FOLDER, f'{session_id}_6_final_2channel.jpg')
    # L∆∞u ·∫£nh 2 channel d∆∞·ªõi d·∫°ng visualization (ch·ªâ hi·ªÉn th·ªã channel ƒë·∫ßu - grayscale)
    cv2.imwrite(final_path, grayscale_image)
    processed_images['6_final_input'] = image_to_base64(final_path)
    saved_paths['6_final_input'] = final_path
    
    return processed_images, final_image, grayscale_image, saved_paths

def predict_fruit(image_2channel, top_k=5):
    """
    H√†m d·ª± ƒëo√°n lo·∫°i qu·∫£ t·ª´ ·∫£nh 2 channel ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω, tr·∫£ v·ªÅ top k d·ª± ƒëo√°n h√†ng ƒë·∫ßu.
    
    Parameters:
        image_2channel: numpy array shape (100, 100, 2) - ·∫£nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (grayscale + edge)
        top_k: s·ªë l∆∞·ª£ng k·∫øt qu·∫£ top cao nh·∫•t c·∫ßn tr·∫£ v·ªÅ (m·∫∑c ƒë·ªãnh 5)
    
    Returns:
        top_predictions: list c√°c dict ch·ª©a 'class' v√† 'confidence' s·∫Øp x·∫øp theo confidence gi·∫£m d·∫ßn
    """
    if model is None or label_encoder is None:
        return None
    
    # Ki·ªÉm tra shape c·ªßa ·∫£nh ƒë·∫ßu v√†o
    if image_2channel.shape != (100, 100, 2):
        print(f"‚ö†Ô∏è  Warning: Image shape {image_2channel.shape} kh√¥ng ƒë√∫ng, c·∫ßn (100, 100, 2)")
        return None
    
    # Chu·∫©n h√≥a (chia 255.0 gi·ªëng l√∫c train) - QUAN TR·ªåNG
    input_img = image_2channel.astype('float32') / 255.0
    
    # M·ªü r·ªông chi·ªÅu batch (1, 100, 100, 2)
    input_batch = np.expand_dims(input_img, axis=0)
    
    # D·ª± ƒëo√°n
    predictions = model.predict(input_batch, verbose=0)
    probabilities = predictions[0]  # L·∫•y m·∫£ng x√°c su·∫•t cho m·ªôt ·∫£nh ƒë·∫ßu v√†o
    
    # S·∫Øp x·∫øp c√°c x√°c su·∫•t v√† l·∫•y ch·ªâ s·ªë c·ªßa top k d·ª± ƒëo√°n h√†ng ƒë·∫ßu
    top_k_indices = np.argsort(probabilities)[::-1][:top_k]
    top_k_probabilities = probabilities[top_k_indices]
    
    # L·∫•y t√™n l·ªõp t∆∞∆°ng ·ª©ng cho top k d·ª± ƒëo√°n h√†ng ƒë·∫ßu
    top_k_labels = label_encoder.inverse_transform(top_k_indices)
    
    # T·∫°o danh s√°ch k·∫øt qu·∫£
    top_predictions = []
    for i in range(len(top_k_labels)):
        top_predictions.append({
            'class': str(top_k_labels[i]),
            'confidence': round(float(top_k_probabilities[i]) * 100, 2)  # Chuy·ªÉn th√†nh ph·∫ßn trƒÉm
        })
    
    return top_predictions

@app.route('/health', methods=['GET'])
def health_check():
    """Endpoint ki·ªÉm tra server c√≥ ho·∫°t ƒë·ªông kh√¥ng"""
    return jsonify({
        'status': 'ok',
        'message': 'Server is running',
        'model_loaded': model is not None,
        'encoder_loaded': label_encoder is not None
    })

@app.route('/predict', methods=['POST'])
def predict():
    """
    Endpoint nh·∫≠n ·∫£nh v√† tr·∫£ v·ªÅ k·∫øt qu·∫£ d·ª± ƒëo√°n c√πng c√°c ·∫£nh ƒë√£ x·ª≠ l√Ω
    
    Request:
        - file: ·∫£nh upload (multipart/form-data)
    
    Response:
        - prediction: t√™n lo·∫°i tr√°i c√¢y
        - confidence: ƒë·ªô tin c·∫≠y
        - processed_images: dict c√°c ·∫£nh ƒë√£ x·ª≠ l√Ω (base64)
        - error: th√¥ng b√°o l·ªói (n·∫øu c√≥)
    """
    try:
        # Ki·ªÉm tra c√≥ file trong request kh√¥ng
        if 'file' not in request.files:
            return jsonify({'error': 'Kh√¥ng c√≥ file ·∫£nh trong request'}), 400
        
        file = request.files['file']
        
        # Ki·ªÉm tra file c√≥ t√™n kh√¥ng
        if file.filename == '':
            return jsonify({'error': 'Kh√¥ng c√≥ file ƒë∆∞·ª£c ch·ªçn'}), 400
        
        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng file
        if not allowed_file(file.filename):
            return jsonify({'error': 'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. Ch·ªâ ch·∫•p nh·∫≠n: PNG, JPG, JPEG, GIF, BMP'}), 400
        
        # L∆∞u file t·∫°m
        filename = secure_filename(file.filename)
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        file.save(filepath)
        
        # X·ª≠ l√Ω ·∫£nh qua c√°c b∆∞·ªõc (ƒë·ªÉ hi·ªÉn th·ªã c√°c b∆∞·ªõc x·ª≠ l√Ω cho frontend)
        processed_images, final_image, grayscale_image, saved_paths = process_image_with_steps(filepath)
        
        if final_image is None:
            return jsonify({'error': 'Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh'}), 500
        
        # D·ª± ƒëo√°n - s·ª≠ d·ª•ng final_image ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (tr√°nh x·ª≠ l√Ω l·∫°i)
        top_predictions = predict_fruit(final_image, top_k=5)
        
        if top_predictions is None:
            return jsonify({'error': 'Kh√¥ng th·ªÉ d·ª± ƒëo√°n. Model ch∆∞a ƒë∆∞·ª£c load'}), 500
        
        # L·∫•y k·∫øt qu·∫£ cao nh·∫•t ƒë·ªÉ hi·ªÉn th·ªã trong message
        top_result = top_predictions[0] if top_predictions else None
        
        # X√≥a file t·∫°m sau khi x·ª≠ l√Ω xong
        try:
            os.remove(filepath)
            # X√≥a c√°c file processed sau khi ƒë√£ encode base64
            for path in saved_paths.values():
                if os.path.exists(path):
                    os.remove(path)
        except Exception as e:
            print(f"L·ªói khi x√≥a file t·∫°m: {e}")
        
        # Tr·∫£ v·ªÅ k·∫øt qu·∫£
        return jsonify({
            'success': True,
            'top_predictions': top_predictions,  # Danh s√°ch top 5 k·∫øt qu·∫£
            'prediction': top_result['class'] if top_result else None,  # K·∫øt qu·∫£ cao nh·∫•t (ƒë·ªÉ t∆∞∆°ng th√≠ch)
            'confidence': top_result['confidence'] if top_result else None,  # ƒê·ªô tin c·∫≠y cao nh·∫•t (ƒë·ªÉ t∆∞∆°ng th√≠ch)
            'processed_images': processed_images,
            'message': f'D·ª± ƒëo√°n t·ªët nh·∫•t: {top_result["class"]} v·ªõi ƒë·ªô tin c·∫≠y {top_result["confidence"]}%' if top_result else 'Kh√¥ng c√≥ k·∫øt qu·∫£'
        })
        
    except Exception as e:
        return jsonify({
            'error': f'L·ªói khi x·ª≠ l√Ω: {str(e)}'
        }), 500

if __name__ == '__main__':
    # Load model khi kh·ªüi ƒë·ªông
    load_model_and_encoder()
    
    # Ch·∫°y server
    print("=" * 50)
    print("Flask Server ƒëang kh·ªüi ƒë·ªông...")
    print("=" * 50)
    print(f"Model: {MODEL_PATH}")
    print(f"Label Encoder: {LABEL_ENCODER_PATH}")
    print("=" * 50)
    print("Server ƒëang ch·∫°y t·∫°i: http://localhost:5000")
    print("Endpoint d·ª± ƒëo√°n: POST http://localhost:5000/predict")
    print("Endpoint health check: GET http://localhost:5000/health")
    print("=" * 50)
    
    app.run(debug=True, host='0.0.0.0', port=5000)

